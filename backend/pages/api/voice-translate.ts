// è¯­éŸ³ç¿»è¯‘API - æ•´åˆè¯­éŸ³è¯†åˆ«ã€ç¿»è¯‘å’ŒTTSåŠŸèƒ½
import formidable from 'formidable';
import fs from 'fs';
import { NextApiRequest, NextApiResponse } from 'next';
import OpenAI from 'openai';

// Next.js è‡ªåŠ¨åŠ è½½ç¯å¢ƒå˜é‡ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®

// ç¦ç”¨Next.jsé»˜è®¤çš„bodyParserï¼Œè®©æˆ‘ä»¬æ‰‹åŠ¨å¤„ç†multipartæ•°æ®
export const config = {
  api: {
    bodyParser: false,
  },
};

// OpenAIå®¢æˆ·ç«¯ - æ·»åŠ ç¯å¢ƒå˜é‡æ£€æŸ¥
if (!process.env.OPENAI_API_KEY) {
  console.error('âŒ OPENAI_API_KEY ç¯å¢ƒå˜é‡æœªè®¾ç½®');
  throw new Error('OPENAI_API_KEY environment variable is not set');
}

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// è¯­è¨€ä»£ç æ˜ å°„
const LANGUAGE_MAP: Record<string, string> = {
  'zh': 'Chinese',
  'en': 'English',
  'ja': 'Japanese',
  'ko': 'Korean',
  'es': 'Spanish',
  'fr': 'French',
  'de': 'German',
  'it': 'Italian',
  'pt': 'Portuguese',
  'ru': 'Russian',
  'ar': 'Arabic',
  'hi': 'Hindi',
  'th': 'Thai',
  'vi': 'Vietnamese',
  'id': 'Indonesian',
  'ms': 'Malay',
  'tl': 'Filipino',
  'tr': 'Turkish',
  'pl': 'Polish',
  'nl': 'Dutch',
  'sv': 'Swedish',
  'da': 'Danish',
  'no': 'Norwegian',
  'fi': 'Finnish',
  'cs': 'Czech',
  'hu': 'Hungarian',
  'ro': 'Romanian',
  'bg': 'Bulgarian',
  'hr': 'Croatian',
  'sk': 'Slovak',
  'sl': 'Slovenian',
  'et': 'Estonian',
  'lv': 'Latvian',
  'lt': 'Lithuanian',
};

// è¯­è¨€ä»£ç è½¬æ¢å‡½æ•°
function convertToWhisperLanguageCode(langCode: string): string {
  const mapping: Record<string, string> = {
    'zh-CN': 'zh',
    'zh-TW': 'zh',
    'en-US': 'en',
    'en-GB': 'en',
    'ja-JP': 'ja',
    'ko-KR': 'ko',
    'es-ES': 'es',
    'fr-FR': 'fr',
    'de-DE': 'de',
    'it-IT': 'it',
    'pt-PT': 'pt',
    'ru-RU': 'ru',
    'ar-SA': 'ar',
    'hi-IN': 'hi',
    'th-TH': 'th',
    'vi-VN': 'vi',
    'id-ID': 'id',
    'ms-MY': 'ms',
    'tl-PH': 'tl',
    'tr-TR': 'tr',
    'pl-PL': 'pl',
    'nl-NL': 'nl',
    'sv-SE': 'sv',
    'da-DK': 'da',
    'no-NO': 'no',
    'fi-FI': 'fi',
    'cs-CZ': 'cs',
    'hu-HU': 'hu',
    'ro-RO': 'ro',
    'bg-BG': 'bg',
    'hr-HR': 'hr',
    'sk-SK': 'sk',
    'sl-SI': 'sl',
    'et-EE': 'et',
    'lv-LV': 'lv',
    'lt-LT': 'lt',
  };
  
  return mapping[langCode] || langCode;
}

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    console.log('ğŸ¤ å¼€å§‹å¤„ç†è¯­éŸ³ç¿»è¯‘è¯·æ±‚');

    // è§£æmultipartè¡¨å•æ•°æ®
    const form = formidable({
      maxFileSize: 25 * 1024 * 1024, // 25MB
      keepExtensions: true,
    });

    const [fields, files] = await form.parse(req);
    
    console.log('ğŸ“‹ è¡¨å•å­—æ®µ:', fields);
    console.log('ğŸ“ æ–‡ä»¶ä¿¡æ¯:', Object.keys(files));

    const audioFile = Array.isArray(files.file) ? files.file[0] : files.file;
    const sourceLang = Array.isArray(fields.sourceLang) ? fields.sourceLang[0] : fields.sourceLang;
    const targetLang = Array.isArray(fields.targetLang) ? fields.targetLang[0] : fields.targetLang;

    if (!audioFile) {
      return res.status(400).json({ error: 'No audio file provided' });
    }

    if (!sourceLang) {
      return res.status(400).json({ error: 'No source language provided' });
    }

    if (!targetLang) {
      return res.status(400).json({ error: 'No target language provided' });
    }

    console.log('ğŸµ éŸ³é¢‘æ–‡ä»¶:', {
      originalFilename: audioFile.originalFilename,
      filepath: audioFile.filepath,
      mimetype: audioFile.mimetype,
      size: audioFile.size
    });

    // 1ï¸âƒ£ è¯­éŸ³è¯†åˆ«ï¼ˆWhisperï¼‰
    console.log('ğŸ” å¼€å§‹è¯­éŸ³è¯†åˆ«...');
    
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼Œç¡®ä¿æœ‰æ­£ç¡®çš„æ‰©å±•å
    const tempFilePath = audioFile.filepath + '.m4a';
    fs.copyFileSync(audioFile.filepath, tempFilePath);
    
    const audioStream = fs.createReadStream(tempFilePath);
    
    // æ·»åŠ è¶…æ—¶è®¾ç½®
    const transcriptPromise = openai.audio.transcriptions.create({
      file: audioStream,
      model: "whisper-1",
      language: convertToWhisperLanguageCode(sourceLang),
    });
    
    // è®¾ç½®30ç§’è¶…æ—¶
    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('OpenAI API timeout after 30 seconds')), 30000);
    });
    
    const transcript = await Promise.race([transcriptPromise, timeoutPromise]) as { text: string; language?: string };

    const sourceText = transcript.text;
    const detectedLang = transcript.language;

    console.log('âœ… è¯­éŸ³è¯†åˆ«å®Œæˆ:', {
      sourceText,
      detectedLang,
      sourceLang,
      targetLang
    });

    // æ£€æŸ¥è¯†åˆ«åˆ°çš„æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆ
    if (!sourceText || sourceText.trim().length < 2) {
      return res.status(400).json({ 
        error: 'No valid speech detected',
        sourceText: sourceText || ''
      });
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯æ— æ•ˆçš„é‡å¤æ–‡æœ¬ï¼ˆå¦‚"..."ï¼‰
    const trimmedText = sourceText.trim();
    if (trimmedText === '...' || 
        trimmedText.match(/^\.{3,}$/) || // 3ä¸ªæˆ–æ›´å¤šç‚¹
        trimmedText.match(/^(\.\s*){3,}$/) || // é‡å¤çš„". "
        trimmedText.toLowerCase().includes('thank you for watching') ||
        trimmedText.toLowerCase().includes('thanks for watching') ||
        trimmedText.toLowerCase().includes('è°¢è°¢è§‚çœ‹')) {
      return res.status(400).json({ 
        error: 'Invalid speech content detected',
        sourceText: trimmedText
      });
    }

    // 2ï¸âƒ£ ç¿»è¯‘ï¼ˆGPT-4o-miniï¼‰
    console.log('ğŸŒ å¼€å§‹ç¿»è¯‘...');
    
    const sourceLangName = LANGUAGE_MAP[detectedLang] || detectedLang;
    const targetLangName = LANGUAGE_MAP[targetLang] || targetLang;

    const translationPromise = openai.chat.completions.create({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: `You are a professional translator. Translate the following ${sourceLangName} text into ${targetLangName}. Keep it natural and accurate. Return only the translated text, nothing else.`
        },
        { 
          role: "user", 
          content: sourceText 
        }
      ],
      temperature: 0.3,
      max_tokens: 1000,
    });
    
    // è®¾ç½®20ç§’è¶…æ—¶
    const translationTimeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Translation API timeout after 20 seconds')), 20000);
    });
    
    const translation = await Promise.race([translationPromise, translationTimeoutPromise]);

    const translatedText = translation.choices[0]?.message?.content?.trim();

    if (!translatedText) {
      throw new Error('No translation received from OpenAI');
    }

    console.log('âœ… ç¿»è¯‘å®Œæˆ:', translatedText);

    // 3ï¸âƒ£ TTSç”±å‰ç«¯ç³»ç»Ÿå¤„ç†

    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try {
      fs.unlinkSync(audioFile.filepath);
      fs.unlinkSync(tempFilePath);
    } catch (cleanupError) {
      console.warn('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
    }

    // è¿”å›ç»“æœ
    const result = {
      success: true,
      data: {
        sourceText,
        detectedLang,
        translatedText,
        confidence: 0.95,
        sourceLanguage: detectedLang,
        targetLanguage: targetLang,
      }
    };

    console.log('ğŸ‰ è¯­éŸ³ç¿»è¯‘å®Œæˆ');
    return res.status(200).json(result);

  } catch (error) {
    console.error('âŒ è¯­éŸ³ç¿»è¯‘å¤±è´¥:', error);
    
    // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try {
      if (req.files?.file) {
        const audioFile = Array.isArray(req.files.file) ? req.files.file[0] : req.files.file;
        if (audioFile.filepath) {
          fs.unlinkSync(audioFile.filepath);
        }
      }
    } catch (cleanupError) {
      console.warn('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError);
    }

    return res.status(500).json({
      success: false,
      error: {
        code: 'VOICE_TRANSLATION_ERROR',
        message: error instanceof Error ? error.message : 'Voice translation failed',
      },
    });
  }
}
